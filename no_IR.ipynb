{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# Settings & Imports\n",
    "# ####################################\n",
    "\n",
    "# Imports from __future__ in case we're running Python 2\n",
    "from __future__ import division, print_function\n",
    "from __future__ import absolute_import, unicode_literals\n",
    "\n",
    "# import my own helper functions\n",
    "from read import read_sims_result\n",
    "from clean import cleanup_0IR_exp\n",
    "from clean import cleanup_0IR_single\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "\n",
    "# Import pyplot for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import logistic regression from scikit learn \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import model selection stuff from scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import feature selection stuff from scikit learn\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# sklearn.metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "# %config InlineBackend.figure_formats = {'svg',}\n",
    "\n",
    "# This enables high resolution PNGs. SVG is preferred, but has problems\n",
    "# rendering vertical and horizontal lines\n",
    "# %config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# remove some pandas warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to construct a model to estimate the probability of default based on some parameter when this is no borrowing or lending.\n",
    "\n",
    "First, let's read and clean up the data.\n",
    "\n",
    "Then, we observe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# Read input, toggle env variable here\n",
    "# ####################################\n",
    "train_on_file = \"0622/0IR300s\"\n",
    "df = read_sims_result(\"/Users/xcheng/Documents/Oberlin/honors/DataAnalysis/data/\"+train_on_file, 32)\n",
    "df2 = cleanup_0IR_exp(df, numSim=300, balanced=False, debts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# Make Sure There is NO DEBT in this 0IR simulation\n",
    "# ####################################\n",
    "# df3 = df[df[\"defaults due to negative wealth\"] # filter default rows\n",
    "#   +df[\"defaults due to deposit shock\"]\n",
    "#   +df['defaults due to interest'] == 0].copy()\n",
    "# for col in df.columns.values[:31]:\n",
    "#     print('{0:5s} {1:15f} {2:15f}'.format(col, df3[col].sum(), df[col].sum()))\n",
    "# print(\"total debt to pay:\", df3[\"debt to pay\"].sum())\n",
    "# print(\"total debt owed:\", df3[\"debt owed\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# look at how things differ for banks with different level of risk aversion\n",
    "# ####################################\n",
    "# avg_by_bank = df2.groupby('theta (risk aversion)').mean()\n",
    "# avg_by_bank[[\"default-next-wealth\", \"default-next-deposit\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Frequency & Reason of Default for Each Bank\"\n",
    "# )\n",
    "# avg_by_bank[[\"wealth\", \"deposits\", \"cash\", \"assets\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Investment Decisions for Each Bank\"\n",
    "# )\n",
    "# avg_by_bank[[\"credit available\", \"credit issued\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Credit Condition for Each Bank\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# look at the plots for correlation\n",
    "# ####################################\n",
    "\n",
    "# to see how independent variables correlate with each other \n",
    "# plt.scatter(df2[\"cash\"], df2[\"credit available\"])\n",
    "# plt.scatter(df2[\"assets\"], df2[\"credit available\"])\n",
    "# plt.scatter(df2[\"deposits\"], df2[\"credit available\"])\n",
    "# plt.scatter(df2[\"cash\"], df2[\"assets\"])\n",
    "# plt.scatter (df2[\"cash\"], df2[\"deposits\"])\n",
    "# plt.scatter(df2[\"deposits\"], df2[\"assets\"])\n",
    "\n",
    "# to see how dependent variable relates to independent variables\n",
    "# plt.scatter(df2[\"default-next\"], df2[\"cash\"])\n",
    "# plt.scatter(df2[\"default-next\"], df2[\"assets\"])\n",
    "# plt.scatter(df2[\"default-next\"], df2[\"deposits\"])\n",
    "# plt.scatter(df2[\"default-next\"], df2[\"wealth\"])\n",
    "\n",
    "# plot settings\n",
    "# plt.yscale(\"symlog\")\n",
    "# plt.xscale(\"symlog\")\n",
    "# plt.rcParams[\"figure.figsize\"] = [25,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# look at how things differ during each period\n",
    "# ####################################\n",
    "\n",
    "# Plot time vs default\n",
    "# df2['period'].hist(by=df2['default-next'], bins=14,  rwidth=0.7, stacked=True)\n",
    "\n",
    "# Plot time vs independent variables\n",
    "# avg_by_time = df2.groupby('period').mean()\n",
    "# avg_by_time[[\"default-next-wealth\", \"default-next-deposit\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Frequency & Reason of Default During Each Period\"\n",
    "# )\n",
    "# avg_by_time[[\"wealth\", \"deposits\", \"cash\", \"assets\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Investment Decisions During Each Period\"\n",
    "# )\n",
    "# avg_by_time[[\"credit available\", \"credit issued\"]].plot(\n",
    "#     kind=\"line\", \n",
    "#     figsize=(12,8),\n",
    "#     title=\"Credit Condition During Each Period\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative wealth not default\n",
    "# df[df[\"wealth\"]<0].loc[1:10000,\"period\":]\n",
    "# df2[df2[\"wealth\"]<=0][\"wealth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come back from 0 wealth\n",
    "# df2[df2[\"theta (risk aversion)\"]==0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing about negative wealth is due to the haircut in asset when calculating wealth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of default vs non-default cases\n",
    "# df2.groupby('default-next').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to figure out whether there is Multicollinearity\n",
    "# df2[\"cash\"]+df2[\"assets\"]*0.8-df2[\"deposits\"]-df2[\"wealth\"]\n",
    "# np.linalg.eig(X.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################\n",
    "# look at the data\n",
    "# ####################################\n",
    "# k=1\n",
    "# sim1 = df.loc[k*15*31:(k+1)*15*31-1]\n",
    "# sim1_ready = cleanup_0IR_single(sim1, 32)\n",
    "# sim1_ready[sim1_ready[\"theta (risk aversion)\"] == 0.05]\n",
    "# sim2 = df.loc[49*15*31:50*15*31-1].copy().reset_index(drop=True)\n",
    "# sim2_ready = cleanup_0IR_single(sim2, 32)\n",
    "# sim2_ready\n",
    "# sim2_ready[sim2_ready[\"theta (risk aversion)\"] == 0.05].loc[:,\"period\":]\n",
    "# df2[df2[\"theta (risk aversion)\"] == 0.05].loc[:,\"period\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to construst a model to predict default (in the next period) in a simulation where there is no lending or borrowing. \n",
    "\n",
    "Variables we can consider includes deposits, cash, assets, credit available, credit issued. \n",
    "\n",
    "I exclude theta (risk aversion) because I think it is private info. \n",
    "\n",
    "I exclude period because I don't think banks should have this information. It feels like cheating.\n",
    "\n",
    "I exclude defaults due to interest, debt to pay, debt owed, over leverages because there is no debt. \n",
    "\n",
    "I exclude credit issued becuase this should not affect anything when there is no debt. \n",
    "\n",
    "I exclude wealth because wealth is a linear combination of deposits, cash and assets.\n",
    "(this might not be true)\n",
    "\n",
    "Let's do a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['period', 'theta (risk aversion)', 'defaults due to interest',\n",
       "       'defaults due to negative wealth', 'defaults due to deposit shock',\n",
       "       'over leverages', 'wealth', 'debt to pay', 'credit available',\n",
       "       'debt owed', 'credit issued', 'deposits', 'cash', 'assets', 'sim#',\n",
       "       'bankID', 'default-next-wealth', 'default-next-deposit',\n",
       "       'default-next-interest', 'leverage', 'dummy-0-leverage',\n",
       "       'over-leverage-frequency', 'wealth-lag', 'deposits-lag', 'cash-lag',\n",
       "       'assets-lag', 'leverage-lag', 'credit-available-lag',\n",
       "       'credit-issued-lag', 'dummy-0-leverage-lag', 'default-next'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables (candidates)\n",
    "independent = [\"deposits\", \"cash\", \"assets\", \"credit available\", \"wealth\", \"leverage\", \n",
    "         \"dummy-0-leverage\",\n",
    "         \"wealth-lag\", \"deposits-lag\", \"cash-lag\", \"assets-lag\", \"leverage-lag\",\n",
    "         \"dummy-0-leverage-lag\",\n",
    "         \"over-leverage-frequency\"]\n",
    "# dependent variable 0\n",
    "dependent = \"default-next\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[independent]\n",
    "y = df2[dependent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output summary statisitics\n",
    "# X.describe().T[['mean', 'min', 'max']].to_csv(\"what.csv\", sep='&', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, there are significantly more non-default cases than default cases after I remove cases where the banks default during the previous periods. Over 98% of the cases are non-default. So when we do cross validation, the model we train would just predict not default every time and still get a very high accuracy. \n",
    "\n",
    "[DONE] Solution : Throw away lots of non-default cases randomly\n",
    "    -> get the same amount of default and non-default cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "# X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sometimes get a warning about complete quasi-separation. What does that mean? Trying to figure out.\n",
    "\n",
    "Once I remove cash as an independent variable, the warning about possible complete quasi-separation goes away. However, I don't think we should readlly care about complete quasi-separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE feature selection\n",
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X,y)\n",
    "# chosen_rfe_X = []\n",
    "# for i in range(1,6):\n",
    "#     rfe = RFE(logreg, i)\n",
    "#     rfe = rfe.fit(X,y)\n",
    "#     print(i, \"feature(s):\", rfe.support_, rfe.ranking_)\n",
    "#     chosen_rfe_X.append(X.columns.values[rfe.support_])\n",
    "# chosen_rfe_X.append(X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with features selected by RFE\n",
    "# for predictors in chosen_rfe_X:\n",
    "#     print(sm.Logit(y, sm.add_constant(df2[predictors])).fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the prediction\n",
    "# m = LogisticRegression()\n",
    "# m.fit(df2[[\"cash\", \"assets\"]], df2[\"default-next\"])\n",
    "# print(m.intercept_, m.coef_)\n",
    "# print(m.predict([[0,50], [50,0],[50,50],[-100,-100],[1000,1000]]))\n",
    "# print(m.predict_proba([[10,0.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################\n",
    "# K-fold cross validation\n",
    "# ##############################\n",
    "# fold = 9\n",
    "# kf = KFold(n_splits=fold, shuffle=True)\n",
    "\n",
    "# for pp in chosen_rfe_X[1:]:\n",
    "#     xx = df2[pp]\n",
    "#     score = 0\n",
    "# #     f1 = 0\n",
    "#     con = np.array([[0, 0], [0, 0]])\n",
    "# #     mat = 0\n",
    "#     brier = 0\n",
    "#     for train_index, test_index in kf.split(xx):\n",
    "#         logreg = LogisticRegression()\n",
    "#         logreg.fit(xx.iloc[train_index], y.iloc[train_index])\n",
    "#         score += logreg.score(xx.iloc[test_index], y.iloc[test_index])\n",
    "#         con += confusion_matrix(y.iloc[test_index], logreg.predict(xx.iloc[test_index]))\n",
    "# #         f1 += f1_score(y.iloc[test_index], logreg.predict(xx.iloc[test_index]))\n",
    "# #         mat += matthews_corrcoef(y.iloc[test_index], logreg.predict(xx.iloc[test_index]))\n",
    "#         brier += brier_score_loss(y.iloc[test_index], logreg.predict(xx.iloc[test_index]))\n",
    "#     print(\"{}\\n {}\\n accuracy:{:24}\\n  brier:{:24}\\n\".format(\n",
    "#         xx.columns.values, con, score/fold, brier/fold))\n",
    "    \n",
    "\n",
    "# for p in X.columns.values:\n",
    "#     xx = df2[p].values.reshape(-1, 1)\n",
    "#     score = 0\n",
    "# #     f1 = 0\n",
    "#     con = np.array([[0, 0], [0, 0]])\n",
    "#     brier = 0\n",
    "#     for train_index, test_index in kf.split(xx):\n",
    "#         logreg = LogisticRegression()\n",
    "#         logreg.fit(xx[train_index], y[train_index])\n",
    "#         score += logreg.score(xx[test_index], y[test_index])\n",
    "#         con += confusion_matrix(y[test_index], logreg.predict(xx[test_index]))\n",
    "# #         f1 += f1_score(y[test_index], logreg.predict(xx[test_index]))\n",
    "#         brier += brier_score_loss(y[test_index], logreg.predict(xx[test_index]))\n",
    "#     print(\"{}\\n {}\\n accuracy:{:24}\\n brier:{:24}\\n\".format(\n",
    "#         p, con, score/fold, brier/fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################\n",
    "# look at the pattern in defaults across different simulation\n",
    "# ##############################\n",
    "# df2[df2[\"default-next\"]==1].loc[:,\"sim#\"].plot(kind='hist',\n",
    "#                                                title=\"# of defaulted banks during each simulation\",\n",
    "#                                                bins=300, \n",
    "#                                                figsize=(16, 6)\n",
    "#                                               )\n",
    "# df2[df2[\"default-next\"]==1].plot(kind='scatter', \n",
    "#                                  x=\"sim#\",\n",
    "#                                  y=\"period\", \n",
    "#                                  figsize=(16,6),\n",
    "#                                  title=\"The periods that defaults happen during each simulation\"\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103257     89]\n",
      " [  1060     71]]\n",
      " accuracy:      0.9890023512042108\n",
      " brier:    0.010997648795789142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deposits</th>\n",
       "      <th>cash</th>\n",
       "      <th>assets</th>\n",
       "      <th>credit available</th>\n",
       "      <th>wealth</th>\n",
       "      <th>leverage</th>\n",
       "      <th>dummy-0-leverage</th>\n",
       "      <th>wealth-lag</th>\n",
       "      <th>deposits-lag</th>\n",
       "      <th>cash-lag</th>\n",
       "      <th>assets-lag</th>\n",
       "      <th>leverage-lag</th>\n",
       "      <th>dummy-0-leverage-lag</th>\n",
       "      <th>over-leverage-frequency</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00405699</td>\n",
       "      <td>0.0187464</td>\n",
       "      <td>-0.00295503</td>\n",
       "      <td>-0.0972679</td>\n",
       "      <td>0.0125242</td>\n",
       "      <td>-0.347231</td>\n",
       "      <td>-0.036873</td>\n",
       "      <td>0.000180019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00360895</td>\n",
       "      <td>-0.0285629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.15878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00424096</td>\n",
       "      <td>0.0199552</td>\n",
       "      <td>-0.000702847</td>\n",
       "      <td>-0.110804</td>\n",
       "      <td>0.0120581</td>\n",
       "      <td>-0.290797</td>\n",
       "      <td>-0.0363759</td>\n",
       "      <td>0.00052051</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00537493</td>\n",
       "      <td>-0.0280979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.10436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00392597</td>\n",
       "      <td>0.019634</td>\n",
       "      <td>-0.00367666</td>\n",
       "      <td>-0.0989065</td>\n",
       "      <td>0.0209843</td>\n",
       "      <td>-0.314829</td>\n",
       "      <td>-0.0409095</td>\n",
       "      <td>0.000979653</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00582258</td>\n",
       "      <td>-0.046779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.10975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00320477</td>\n",
       "      <td>0.020037</td>\n",
       "      <td>-0.00469506</td>\n",
       "      <td>-0.106832</td>\n",
       "      <td>0.0148513</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>-0.0372141</td>\n",
       "      <td>0.000251162</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00498773</td>\n",
       "      <td>-0.0332982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.13537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00370993</td>\n",
       "      <td>0.0186168</td>\n",
       "      <td>-0.00361191</td>\n",
       "      <td>-0.109528</td>\n",
       "      <td>0.0105363</td>\n",
       "      <td>-0.300851</td>\n",
       "      <td>-0.0281913</td>\n",
       "      <td>0.000394699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00429308</td>\n",
       "      <td>-0.0246577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.16443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00415379</td>\n",
       "      <td>0.0192308</td>\n",
       "      <td>-0.00574917</td>\n",
       "      <td>-0.0958207</td>\n",
       "      <td>0.0135407</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.0373825</td>\n",
       "      <td>0.000608729</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00472521</td>\n",
       "      <td>-0.0317393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.14994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00432058</td>\n",
       "      <td>0.0199607</td>\n",
       "      <td>-0.00281846</td>\n",
       "      <td>-0.111233</td>\n",
       "      <td>0.0127892</td>\n",
       "      <td>-0.295612</td>\n",
       "      <td>-0.0368266</td>\n",
       "      <td>0.000453305</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00528737</td>\n",
       "      <td>-0.0288377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.07798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00386932</td>\n",
       "      <td>0.0200215</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0993416</td>\n",
       "      <td>0.0107413</td>\n",
       "      <td>-0.310735</td>\n",
       "      <td>-0.0406549</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.24892e-05</td>\n",
       "      <td>-0.00551553</td>\n",
       "      <td>-0.0235118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.16122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00308033</td>\n",
       "      <td>0.0188581</td>\n",
       "      <td>-0.00319111</td>\n",
       "      <td>-0.108086</td>\n",
       "      <td>0.0107348</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>-0.03084</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00035885</td>\n",
       "      <td>-0.00391553</td>\n",
       "      <td>-0.0240731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.17471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.0039798</td>\n",
       "      <td>0.0196217</td>\n",
       "      <td>-0.00327363</td>\n",
       "      <td>-0.101557</td>\n",
       "      <td>0.0132482</td>\n",
       "      <td>-0.370622</td>\n",
       "      <td>-0.0385347</td>\n",
       "      <td>0.000714742</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00539658</td>\n",
       "      <td>-0.039921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.06451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00387798</td>\n",
       "      <td>0.0190716</td>\n",
       "      <td>-0.00441929</td>\n",
       "      <td>-0.0990955</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>-0.302823</td>\n",
       "      <td>-0.036892</td>\n",
       "      <td>0.00040406</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00416733</td>\n",
       "      <td>-0.0290702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.17562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.00408038</td>\n",
       "      <td>0.0195249</td>\n",
       "      <td>-0.00199918</td>\n",
       "      <td>-0.0992441</td>\n",
       "      <td>0.0129949</td>\n",
       "      <td>-0.323865</td>\n",
       "      <td>-0.0384262</td>\n",
       "      <td>0.000596942</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005451</td>\n",
       "      <td>-0.0293871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.14817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deposits        cash     assets credit available     wealth   leverage  \\\n",
       "0         0 -0.00405699  0.0187464      -0.00295503 -0.0972679  0.0125242   \n",
       "1         0 -0.00424096  0.0199552     -0.000702847  -0.110804  0.0120581   \n",
       "2         0 -0.00392597   0.019634      -0.00367666 -0.0989065  0.0209843   \n",
       "3         0 -0.00320477   0.020037      -0.00469506  -0.106832  0.0148513   \n",
       "4         0 -0.00370993  0.0186168      -0.00361191  -0.109528  0.0105363   \n",
       "5         0 -0.00415379  0.0192308      -0.00574917 -0.0958207  0.0135407   \n",
       "6         0 -0.00432058  0.0199607      -0.00281846  -0.111233  0.0127892   \n",
       "7         0 -0.00386932  0.0200215                0 -0.0993416  0.0107413   \n",
       "8         0 -0.00308033  0.0188581      -0.00319111  -0.108086  0.0107348   \n",
       "9         0  -0.0039798  0.0196217      -0.00327363  -0.101557  0.0132482   \n",
       "10        0 -0.00387798  0.0190716      -0.00441929 -0.0990955   0.012744   \n",
       "11        0 -0.00408038  0.0195249      -0.00199918 -0.0992441  0.0129949   \n",
       "\n",
       "   dummy-0-leverage wealth-lag deposits-lag     cash-lag  assets-lag  \\\n",
       "0         -0.347231  -0.036873  0.000180019            0 -0.00360895   \n",
       "1         -0.290797 -0.0363759   0.00052051            0 -0.00537493   \n",
       "2         -0.314829 -0.0409095  0.000979653            0 -0.00582258   \n",
       "3         -0.262991 -0.0372141  0.000251162            0 -0.00498773   \n",
       "4         -0.300851 -0.0281913  0.000394699            0 -0.00429308   \n",
       "5          -0.34531 -0.0373825  0.000608729            0 -0.00472521   \n",
       "6         -0.295612 -0.0368266  0.000453305            0 -0.00528737   \n",
       "7         -0.310735 -0.0406549            0 -8.24892e-05 -0.00551553   \n",
       "8         -0.278604   -0.03084            0  -0.00035885 -0.00391553   \n",
       "9         -0.370622 -0.0385347  0.000714742            0 -0.00539658   \n",
       "10        -0.302823  -0.036892   0.00040406            0 -0.00416733   \n",
       "11        -0.323865 -0.0384262  0.000596942            0   -0.005451   \n",
       "\n",
       "   leverage-lag dummy-0-leverage-lag over-leverage-frequency    const  \n",
       "0    -0.0285629                    0                       0 -3.15878  \n",
       "1    -0.0280979                    0                       0 -3.10436  \n",
       "2     -0.046779                    0                       0 -3.10975  \n",
       "3    -0.0332982                    0                       0 -3.13537  \n",
       "4    -0.0246577                    0                       0 -3.16443  \n",
       "5    -0.0317393                    0                       0 -3.14994  \n",
       "6    -0.0288377                    0                       0 -3.07798  \n",
       "7    -0.0235118                    0                       0 -3.16122  \n",
       "8    -0.0240731                    0                       0 -3.17471  \n",
       "9     -0.039921                    0                       0 -3.06451  \n",
       "10   -0.0290702                    0                       0 -3.17562  \n",
       "11   -0.0293871                    0                       0 -3.14817  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ##############################\n",
    "# Regularization + cross validation \n",
    "# trial and error for the best lambda\n",
    "# ##############################\n",
    "fold = 12\n",
    "inv_reg_strength = 0.007\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "\n",
    "accuracy = 0\n",
    "conf = np.array([[0, 0], [0, 0]])\n",
    "brier = 0\n",
    "co_effs = pd.DataFrame(columns = np.append(X.columns.values, \"const\"), \n",
    "                       index=range(fold))\n",
    "row = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    lasso = LogisticRegression(penalty=\"l1\", C=inv_reg_strength)\n",
    "    lasso.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    new_row = np.append(lasso.coef_, lasso.intercept_)\n",
    "    co_effs.loc[row] = new_row\n",
    "    accuracy += lasso.score(X.iloc[test_index], y.iloc[test_index])\n",
    "    conf += confusion_matrix(y.iloc[test_index], lasso.predict(X.iloc[test_index]))\n",
    "    brier += brier_score_loss(y.iloc[test_index], lasso.predict(X.iloc[test_index]))\n",
    "    row += 1\n",
    "print(\"{}\\n accuracy:{:24}\\n brier:{:24}\\n\".format(\n",
    "        conf, accuracy/fold, brier/fold))\n",
    "co_effs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0007, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ################################\n",
    "# Fit the model on all data\n",
    "# ################################\n",
    "inv_reg_strength = 0.0007\n",
    "final = LogisticRegression(penalty=\"l1\", C=inv_reg_strength)\n",
    "final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deposits</th>\n",
       "      <th>cash</th>\n",
       "      <th>assets</th>\n",
       "      <th>credit available</th>\n",
       "      <th>wealth</th>\n",
       "      <th>leverage</th>\n",
       "      <th>dummy-0-leverage</th>\n",
       "      <th>wealth-lag</th>\n",
       "      <th>deposits-lag</th>\n",
       "      <th>cash-lag</th>\n",
       "      <th>assets-lag</th>\n",
       "      <th>leverage-lag</th>\n",
       "      <th>dummy-0-leverage-lag</th>\n",
       "      <th>over-leverage-frequency</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coefficient</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>0.035445</td>\n",
       "      <td>-0.018639</td>\n",
       "      <td>-0.205266</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.094460</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019053</td>\n",
       "      <td>-0.166881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.785173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.997880</td>\n",
       "      <td>0.995747</td>\n",
       "      <td>-0.189899</td>\n",
       "      <td>-2.786152</td>\n",
       "      <td>0.164262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.197659</td>\n",
       "      <td>0.680074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.463354</td>\n",
       "      <td>-1.267147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.785173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             deposits      cash    assets  credit available    wealth  \\\n",
       "coefficient       0.0 -0.009588  0.035445         -0.018639 -0.205266   \n",
       "importance        0.0 -0.997880  0.995747         -0.189899 -2.786152   \n",
       "\n",
       "             leverage  dummy-0-leverage  wealth-lag  deposits-lag  cash-lag  \\\n",
       "coefficient  0.019904               0.0   -0.094460      0.006865       0.0   \n",
       "importance   0.164262               0.0   -1.197659      0.680074       0.0   \n",
       "\n",
       "             assets-lag  leverage-lag  dummy-0-leverage-lag  \\\n",
       "coefficient   -0.019053     -0.166881                   0.0   \n",
       "importance    -0.463354     -1.267147                   0.0   \n",
       "\n",
       "             over-leverage-frequency     const  \n",
       "coefficient                      0.0 -0.785173  \n",
       "importance                       0.0 -0.785173  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ################################\n",
    "# look at the importance of each variable\n",
    "# importance = coefficient * varaible average\n",
    "# ################################\n",
    "var_imp = pd.DataFrame(columns = np.append(X.columns.values, \"const\"))\n",
    "coeff = np.append(final.coef_, final.intercept_)\n",
    "var_imp.loc[\"coefficient\"] = coeff\n",
    "var_imp.loc[\"importance\"] = coeff * np.append(np.array(X.mean()), 1)\n",
    "var_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp.T[var_imp.T['coefficient']!=0].to_csv(\"inpaper.csv\", sep='&', float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################\n",
    "# Read input for 1 interest rate\n",
    "# ##############################\n",
    "df_1 =  read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0625/1IR\", 32)\n",
    "df_1c = cleanup_0IR_exp(df_1, numSim=50, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize prediction results\n",
    "# plt.hist(list(map(lambda x: x[1], final.predict_proba(df_1c[df_1c[\"default-next\"]==0][independent]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9267543859649123\n",
      "[[16747  1332]\n",
      " [    4   157]]\n",
      "0.07324561403508772\n"
     ]
    }
   ],
   "source": [
    "# ##############################\n",
    "# Examine the prediction interest rate\n",
    "# ##############################\n",
    "print(final.score(df_1c[independent], df_1c[dependent]))\n",
    "print(confusion_matrix(df_1c[dependent], final.predict(df_1c[independent])))\n",
    "print(brier_score_loss(df_1c[dependent], final.predict(df_1c[independent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################\n",
    "# Read input for 2 interest rates\n",
    "# ##############################\n",
    "df_2 =  read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0625/2IR\", 32)\n",
    "df_2c = cleanup_0IR_exp(df_2, numSim=50, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9244439538605883\n",
      "[[16594  1362]\n",
      " [    7   156]]\n",
      "0.07555604613941166\n"
     ]
    }
   ],
   "source": [
    "# ##############################\n",
    "# Examine the prediction for 2 interest rates\n",
    "# ##############################\n",
    "print(final.score(df_2c[independent], df_2c[dependent]))\n",
    "print(confusion_matrix(df_2c[dependent], final.predict(df_2c[independent])))\n",
    "print(brier_score_loss(df_2c[dependent], final.predict(df_2c[independent])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the prediction is fairly good.\n",
    "\n",
    "We have a lot of false negatives, but hopefully the network part would help with this.\n",
    "\n",
    "An interesting observation: the more sample we have in 0IR, the more false negatives, the less true negatives we get (less accurate predictions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
