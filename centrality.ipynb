{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# import my own helper functions\n",
    "from read import read_sims_result\n",
    "from clean import cleanup_0IR_exp\n",
    "from clean import cleanup_network\n",
    "\n",
    "# pearson correlation coeffcient\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# deque\n",
    "from collections import deque\n",
    "\n",
    "# deep copy\n",
    "from copy import deepcopy\n",
    "\n",
    "# random [0,1)\n",
    "from random import random\n",
    "\n",
    "# Page Rank\n",
    "from networkx.algorithms.link_analysis.pagerank_alg import pagerank, pagerank_numpy, pagerank_scipy\n",
    "\n",
    "# distance\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "independent = [\"deposits\", \"cash\", \"assets\", \"credit available\", \"wealth\", \"leverage\", \n",
    "         \"dummy-0-leverage\",\n",
    "         \"wealth-lag\", \"deposits-lag\", \"cash-lag\", \"assets-lag\", \"leverage-lag\", \n",
    "         \"credit-available-lag\", \"credit-issued-lag\", \"dummy-0-leverage-lag\",\n",
    "         \"over-leverage-frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.007, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###########################\n",
    "# Read OIR results, and fit the model\n",
    "# ###########################\n",
    "df0 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0622/0IR300s\", 32)\n",
    "df0c = cleanup_0IR_exp(df0, numNode=32, numPeriod=15, numSim=100, balanced=True)\n",
    "\n",
    "X = df0c[independent]\n",
    "y = df0c[\"default-next\"]\n",
    "\n",
    "final = LogisticRegression(penalty=\"l1\", C=0.007)\n",
    "final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no defaults in 0IR\n",
    "# sum(df0[df0[\"defaults due to interest\"]\n",
    "#     +df0[\"defaults due to negative wealth\"]\n",
    "#     +df0[\"defaults due to deposit shock\"] == 0].loc[:,\"dot0\":\"dot30\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Read & process positive IR results\n",
    "# ###########################\n",
    "df_1 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0625/1IR\", 32)\n",
    "mx_1n = cleanup_network(df_1, numNode=32, numPeriod=15, numSim=50)\n",
    "df_1c = cleanup_0IR_exp(df_1, numNode=32, numPeriod=15, numSim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_weight(N, dff, mid):\n",
    "    \"\"\"\n",
    "    Calculate weight for edges\n",
    "    Each debt is divided by lenders' wealth (w/o haircut)，\n",
    "    The result number r is scaled to [0, 1) using g(r)=r/(mid+r)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    df: Pandas dataframe (no cleanup)\n",
    "        where we get banks' wealth (w/o haircut)\n",
    "    mid: int\n",
    "        the debt-to-wealth ratio resulting in 50% probability of spreading default\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    dff[\"book_wealth\"] = (dff[\"assets\"] + dff[\"cash\"] + dff[\"debt owed\"] \n",
    "                         - dff[\"debt to pay\"] - dff[\"deposits\"])\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum+1):\n",
    "            for lender in range(bankNum):\n",
    "                w = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==lender)\n",
    "                       ][\"book_wealth\"].values[0]\n",
    "                \n",
    "                # helper function\n",
    "                def f(a):\n",
    "                    if a > 0: # there is debt\n",
    "                        if w > 0: # positive wealth\n",
    "                            t = a/w\n",
    "                            return t/(t+mid)\n",
    "                        else: # 0 or negative wealth\n",
    "                            return 100/(100+mid)\n",
    "                    else: # no debt or weird data \n",
    "                        return 0\n",
    "                \n",
    "                WN[s, p-1, :, lender] = [f(k) for k in WN[s, p-1, :, lender]]\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_weight(N, dff, model, variables):\n",
    "    \"\"\"\n",
    "    Calculate weight for nodes\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    dff: Pandas dataframe (yes cleanup)\n",
    "        where we get bank's balance sheet info\n",
    "    model: model for default probability\n",
    "        scikit learn LogisticRegression\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        array of predicted probability of default\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    WN = np.empty((simNum, periodNum, bankNum))\n",
    "    WN.fill(-1)\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(2,periodNum):\n",
    "            for b in range(bankNum):\n",
    "                X = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==b)\n",
    "                       ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] = predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights_all = create_edge_weight(mx_1n, df_1, 0.6)\n",
    "node_weights_all = create_node_weight(mx_1n, df_1c, final, independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, I discover that it does not matter 0.6 is. I experimented with serveral numbers between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the debt adjacency matrix in a 2d graph\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(edge_weights_all[0,1], interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_single_1a(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW modified random walk algorithm\n",
    "    at the begining of each round, flip coin to cause one solvent bank to default\n",
    "    \n",
    "    This one is aggressive\n",
    "    [[18054    25] ---0625/1IR\n",
    "     [  158     3]]\n",
    "    [[17926    30] ---0625/2IR\n",
    "     [  160     3]]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    defaulted = frozenset([i for i in range(num_bank) if solvent[i] == -1])\n",
    "    tempDefault = set(defaulted)\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "            while len(nextDefault) > 0: # queue not empty\n",
    "                n = nextDefault.popleft() # next on the queue\n",
    "                if n not in tempDefault: # not aleady defaulted\n",
    "                    tempDefault.add(n)\n",
    "                    result[n] += 1\n",
    "                    for s in G.successors(n): # creditors of n\n",
    "                        if s not in tempDefault and coin(G.edges[(n,s)]['weight']):\n",
    "                            nextDefault.append(s)\n",
    "            tempDefault = set(defaulted)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_single_1b(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW modified random walk algorithm\n",
    "    at the begining of each round, flip coin to cause one solvent bank to default\n",
    "    during each round, we can add 1 multiple times\n",
    "    \n",
    "    This one is also aggressive\n",
    "    [[18052    27] ---0625/1IR\n",
    "     [  157     4]]\n",
    "    [[17927    29] ---0625/2IR\n",
    "     [  160     3]]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "            while len(nextDefault) > 0: # queue not empty\n",
    "                n = nextDefault.popleft() # next on the queue\n",
    "                result[n] += 1 # default count ++\n",
    "                for s in G.successors(n): # creditors of n\n",
    "                    if coin(G.edges[(n,s)]['weight']):\n",
    "                        nextDefault.append(s)\n",
    "                        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_single_2a(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    at the begining of each round, flip multiple coins for each solvent bank to make them default\n",
    "    \n",
    "    This one is useless (very progressive):\n",
    "    [[18079     0] ---0625/1IR\n",
    "     [  161     0]]\n",
    "    [[17956     0] ---0625/2IR\n",
    "     [  163     0]]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    defaulted = frozenset([i for i in range(num_bank) if solvent[i] == -1])\n",
    "    tempDefault = set(defaulted)\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "\n",
    "        while len(nextDefault) > 0: # queue not empty\n",
    "            n = nextDefault.popleft() # next on the queue\n",
    "            if n not in tempDefault: # not aleady defaulted\n",
    "                tempDefault.add(n)\n",
    "                result[n] += 1\n",
    "                for s in G.successors(n): # creditors of n\n",
    "                    if s not in tempDefault and coin(G.edges[(n,s)]['weight']):\n",
    "                        nextDefault.append(s)\n",
    "        tempDefault = set(defaulted)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_single_2b(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    at the begining of each round, flip multiple coins for each solvent bank to make them default\n",
    "    during each round, we can add 1 multiple times\n",
    "    \n",
    "    This one is progressive:\n",
    "    [[18048    31] ---0625/1IR\n",
    "     [  157     4]]\n",
    "    [[17926    30] ---0625/2IR\n",
    "     [  157     6]]\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "        while len(nextDefault) > 0: # queue not empty\n",
    "            n = nextDefault.popleft() # next on the queue\n",
    "            result[n] += 1\n",
    "            for s in G.successors(n): # creditors of n\n",
    "                if coin(G.edges[(n,s)]['weight']):\n",
    "                    nextDefault.append(s)\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_walk_exp(N, solvent, random_walk, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: 3D numpy array [n_simulations, n_periods, n_borrowers, n_lenders] \n",
    "        predicted default probability OR -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: 1D numpy array\n",
    "        index for the bank's default probability   \n",
    "    \"\"\"\n",
    "    n_s, n_p, n_b, _ = N.shape\n",
    "    s_s, s_p, s_b = solvent.shape\n",
    "    big_result = []\n",
    "    \n",
    "    if n_s != s_s or n_p != s_p or n_b != s_b:\n",
    "        raise ValueError('Two arrays have incompatible sizes.')\n",
    "        \n",
    "    for i, j in np.ndindex((n_s,n_p)):\n",
    "        big_result.extend(random_walk(N[i,j],\n",
    "                                      solvent[i,j],\n",
    "                                      iterations=iterations\n",
    "                                     ).values())\n",
    "        \n",
    "    return np.array(big_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prediction = customized_random_walk_exp(edge_weights_all, node_weights_all, random_walk_single_1b, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18240"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29103589661409535, 0.0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###########################\n",
    "# pearson correlation coeffcient is not very big \n",
    "# it gets slightly bigger with lots of iterations\n",
    "# ###########################\n",
    "pearsonr(overall_prediction, df_1c[\"default-next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim#</th>\n",
       "      <th>period</th>\n",
       "      <th>bankID</th>\n",
       "      <th>theta (risk aversion)</th>\n",
       "      <th>wealth</th>\n",
       "      <th>deposits</th>\n",
       "      <th>cash</th>\n",
       "      <th>assets</th>\n",
       "      <th>leverage</th>\n",
       "      <th>credit available</th>\n",
       "      <th>...</th>\n",
       "      <th>cash-lag</th>\n",
       "      <th>assets-lag</th>\n",
       "      <th>leverage-lag</th>\n",
       "      <th>credit-available-lag</th>\n",
       "      <th>credit-issued-lag</th>\n",
       "      <th>dummy-0-leverage-lag</th>\n",
       "      <th>over-leverage-frequency</th>\n",
       "      <th>default-next-wealth</th>\n",
       "      <th>default-next-deposit</th>\n",
       "      <th>default-next-interest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default-next</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>...</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sim#  period  bankID  theta (risk aversion)  wealth  deposits  \\\n",
       "default-next                                                                   \n",
       "0             18079   18079   18079                  18079   18079     18079   \n",
       "1               161     161     161                    161     161       161   \n",
       "\n",
       "               cash  assets  leverage  credit available  \\\n",
       "default-next                                              \n",
       "0             18079   18079     18079             18079   \n",
       "1               161     161       161               161   \n",
       "\n",
       "                      ...            cash-lag  assets-lag  leverage-lag  \\\n",
       "default-next          ...                                                 \n",
       "0                     ...               18079       18079         18079   \n",
       "1                     ...                 161         161           161   \n",
       "\n",
       "              credit-available-lag  credit-issued-lag  dummy-0-leverage-lag  \\\n",
       "default-next                                                                  \n",
       "0                            18079              18079                 18079   \n",
       "1                              161                161                   161   \n",
       "\n",
       "              over-leverage-frequency  default-next-wealth  \\\n",
       "default-next                                                 \n",
       "0                               18079                18079   \n",
       "1                                 161                  161   \n",
       "\n",
       "              default-next-deposit  default-next-interest  \n",
       "default-next                                               \n",
       "0                            18079                  18079  \n",
       "1                              161                    161  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1c.groupby(\"default-next\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8275,  4737, 17100, 16427,  1783, 14057,  1068, 16419,  5574,\n",
       "       11613,  2077, 16455,  2072,   603, 16420,  6913,  5545,   377,\n",
       "        9470, 14082,  1070,  8271, 12436, 11976,  7564,  9394,  1811,\n",
       "        9047, 16421,  9683,  2074, 11978,  6623,    93,  9045,  6911,\n",
       "        9393, 17096,  6938,  8821,  3278,  4315,  9424,  3797,  2485,\n",
       "        7300,  5544,  9303, 11167,  2070, 11947,  9049,  9427,  1067,\n",
       "       11168, 14567, 15800, 17095,  6172,  6910,  8706, 12435,   374,\n",
       "       16141,   376,  9423,   378,    90,  9429,  1069, 16283,  9421,\n",
       "        9425, 11170,  6173,  8273, 11858,  8276, 11946,  2486,  6565,\n",
       "        1815,  6167,  8793,   373,  1814, 14568, 16734,  9681, 16454,\n",
       "        2071, 16453,  4739, 17099,  2073,  6174,  4374,  6169,  2455,\n",
       "        4318])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy = df_1c[\"default-next\"]\n",
    "# np.array(range(len(yyy)))[yyy==0]\n",
    "np.random.choice(np.array(range(len(yyy)))[yyy==1],size=100,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_k_fold(X, y, fold=12):\n",
    "    \"\"\"\n",
    "    customized K-fold cross validation \n",
    "    print certain summary statistics\n",
    "    \"\"\"\n",
    "    # k-fold\n",
    "    kf = KFold(n_splits=fold, shuffle=True)\n",
    "\n",
    "    # initialization\n",
    "    accuracy = 0\n",
    "    conf = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "    def g(A, arr):\n",
    "        if A.shape[1] == 1: return A[arr]\n",
    "        else: return A.loc[arr]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        model = LogisticRegression()\n",
    "        model.fit(g(X,train_index), y.iloc[train_index])\n",
    "        print(model.coef_, model.intercept_)\n",
    "\n",
    "        accuracy += model.score(g(X,test_index), y.iloc[test_index])\n",
    "        conf += confusion_matrix(y.iloc[test_index], model.predict(g(X,test_index)))\n",
    "\n",
    "    tn, fp, fn, tp = conf.ravel()\n",
    "    print(\"{}\\n accuracy:{:24}\\n precision:{:24}\\n recall:{:24}\\n\".format(\n",
    "            conf, \n",
    "            accuracy/fold, \n",
    "            tp/(tp+fp),\n",
    "            tp/(tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_k_fold_balanced(X, y, fold=12):\n",
    "    \"\"\"\n",
    "    customized K-fold cross validation \n",
    "    print certain summary statistics\n",
    "    \"\"\"\n",
    "    all_obs = np.array(range(len(y)))\n",
    "    default_obs = all_obs[y==1]\n",
    "    nondefault_obs = np.random.choice(all_obs[y==0],\n",
    "                                     size=len(default_obs),\n",
    "                                     replace=False)\n",
    "    all_index = np.append(default_obs, nondefault_obs)\n",
    "    customized_k_fold(X[all_index], y[all_index], fold=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01240397]] [-3.60380092]\n",
      "[[0.01151696]] [-3.44328164]\n",
      "[[0.01195532]] [-3.56537264]\n",
      "[[0.01144232]] [-3.42357864]\n",
      "[[0.01143624]] [-3.43655865]\n",
      "[[0.01160685]] [-3.40815917]\n",
      "[[0.01153255]] [-3.41380608]\n",
      "[[0.01169909]] [-3.53273655]\n",
      "[[0.01181041]] [-3.45602798]\n",
      "[[0.01176579]] [-3.52899681]\n",
      "[[0.01218029]] [-3.59629783]\n",
      "[[0.01213345]] [-3.54771385]\n",
      "[[150  11]\n",
      " [  7 154]]\n",
      " accuracy:      0.9440883190883191\n",
      " precision:      0.9333333333333333\n",
      " recall:      0.9565217391304348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1111111111111111111111111\n",
    "# K-fold cross validation \n",
    "# use approx. default probability to predict default\n",
    "# ###########################\n",
    "customized_k_fold_balanced(overall_prediction.reshape(-1, 1), df_1c[\"default-next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction based on logistic regression with balanced sheet information\n",
    "bs_prediction_all = node_weights_all.reshape(1,-1)[0]\n",
    "bal_sh_prediction = bs_prediction_all [bs_prediction_all != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip two predictions into a dataframe\n",
    "two_predictions = pd.DataFrame({'balanced sheet':bal_sh_prediction, 'network':overall_prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[   90    93   345   346   372   373   374   376   377   378   603   734\\n   820   903  1067  1068  1069  1070  1071  1143  1722  1783  1811  1813\\n  1814  1815  1817  1818  2070  2071  2072  2073  2074  2075  2076  2077\\n  2455  2485  2486  2540  3218  3249  3250  3278  3600  3797  4315  4318\\n  4374  4737  4739  5544  5545  5574  6167  6168  6169  6170  6171  6172\\n  6173  6174  6565  6623  6909  6910  6911  6912  6913  6938  7300  7302\\n  7329  7330  7331  7563  7564  7565  7567  7592  8271  8272  8273  8275\\n  8276  8706  8793  8821  9044  9045  9047  9049  9152  9303  9393  9394\\n  9421  9423  9424  9425  9427  9428  9429  9430  9431  9457  9470  9681\\n  9683  9708 10079 10080 11167 11168 11170 11171 11612 11613 11614 11858\\n 11946 11947 11948 11975 11976 11977 11978 12405 12433 12434 12435 12436\\n 13822 14027 14057 14082 14110 14567 14568 14597 14598 15800 15830 15942\\n 16141 16142 16283 16419 16420 16421 16424 16427 16453 16454 16455 16734\\n 17095 17096 17099 17100 17723  1626 17593 18170 10726  2997 11560  1556\\n 12268 17201 13768 17437  2469  9257 17783 10399  9810 15623 14139  7504\\n 16110  9834 10669  8181 14422 13027 17731 15350  3170 11801  7946  4461\\n  5702  4077 17352  3730 14815  5855 10770 15312  4051 11741   995  6458\\n  1117   816  5031 16865  2563  1061  9807  5636 12004  7933  6672   123\\n 10312    13  9634  5423 15553  5375  8069  8991  7584 13252  6215 12562\\n  7679  1077  9203  3489  8806 13729  6089  4418   904 13570 15121  8727\\n 16331 15523 11823  5540 12669 16594 10467 11944  1840  7538  5845 14124\\n 16209  8337  2798  4771  8614 17446 16922  2329  6777  7160  8853  7413\\n  9342   884  2106  2505 11721 13856 16826  6835 17619  9210  9212  2199\\n  7532  8205 17418  7181  1226  9364 15677 14495   707 11162 15460  7861\\n 16638 16569 15810  6061  6305 17196  5424  9950  2739   958  5844 16309\\n 17252  9443 15440  5176 11181 10369  3684  1704  4758  5987 12257  6326\\n  2710 10944  6219  5543   412 14905  6235  2909  3178 12751] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-4cdfce7c404e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This does not seem to be an effective approach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ###########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcustomized_k_fold_balanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_1c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default-next\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-29df633b2679>\u001b[0m in \u001b[0;36mcustomized_k_fold_balanced\u001b[0;34m(X, y, fold)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                      replace=False)\n\u001b[1;32m     11\u001b[0m     \u001b[0mall_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnondefault_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcustomized_k_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[   90    93   345   346   372   373   374   376   377   378   603   734\\n   820   903  1067  1068  1069  1070  1071  1143  1722  1783  1811  1813\\n  1814  1815  1817  1818  2070  2071  2072  2073  2074  2075  2076  2077\\n  2455  2485  2486  2540  3218  3249  3250  3278  3600  3797  4315  4318\\n  4374  4737  4739  5544  5545  5574  6167  6168  6169  6170  6171  6172\\n  6173  6174  6565  6623  6909  6910  6911  6912  6913  6938  7300  7302\\n  7329  7330  7331  7563  7564  7565  7567  7592  8271  8272  8273  8275\\n  8276  8706  8793  8821  9044  9045  9047  9049  9152  9303  9393  9394\\n  9421  9423  9424  9425  9427  9428  9429  9430  9431  9457  9470  9681\\n  9683  9708 10079 10080 11167 11168 11170 11171 11612 11613 11614 11858\\n 11946 11947 11948 11975 11976 11977 11978 12405 12433 12434 12435 12436\\n 13822 14027 14057 14082 14110 14567 14568 14597 14598 15800 15830 15942\\n 16141 16142 16283 16419 16420 16421 16424 16427 16453 16454 16455 16734\\n 17095 17096 17099 17100 17723  1626 17593 18170 10726  2997 11560  1556\\n 12268 17201 13768 17437  2469  9257 17783 10399  9810 15623 14139  7504\\n 16110  9834 10669  8181 14422 13027 17731 15350  3170 11801  7946  4461\\n  5702  4077 17352  3730 14815  5855 10770 15312  4051 11741   995  6458\\n  1117   816  5031 16865  2563  1061  9807  5636 12004  7933  6672   123\\n 10312    13  9634  5423 15553  5375  8069  8991  7584 13252  6215 12562\\n  7679  1077  9203  3489  8806 13729  6089  4418   904 13570 15121  8727\\n 16331 15523 11823  5540 12669 16594 10467 11944  1840  7538  5845 14124\\n 16209  8337  2798  4771  8614 17446 16922  2329  6777  7160  8853  7413\\n  9342   884  2106  2505 11721 13856 16826  6835 17619  9210  9212  2199\\n  7532  8205 17418  7181  1226  9364 15677 14495   707 11162 15460  7861\\n 16638 16569 15810  6061  6305 17196  5424  9950  2739   958  5844 16309\\n 17252  9443 15440  5176 11181 10369  3684  1704  4758  5987 12257  6326\\n  2710 10944  6219  5543   412 14905  6235  2909  3178 12751] not in index'"
     ]
    }
   ],
   "source": [
    "# 222222222222222222222222222\n",
    "# K-fold cross validation\n",
    "# use approx. default probability + balanced sheet default prob to predict default\n",
    "# This does not seem to be an effective approach\n",
    "# ###########################\n",
    "customized_k_fold_balanced(two_predictions, df_1c[\"default-next\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining (logsitic regression) balanced sheet default prediction (logisitis regression) with network information (4 modified page rank I created) does not seem to be effective. The result predicts no default, only not default. However, the accuracy is also very high (> 99%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "Stuff Below this are old stuff that I might or might not need.\n",
    "----------------------------------------------------------------------\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_avg_max(N):\n",
    "    \"\"\"\n",
    "    calculate average & max distances between all pair of nodes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_d: 2D numpy array [n_simulations, n_periods]\n",
    "        average distances between all pair of nodes\n",
    "    max_d: 2D numpy array [n_simulations, n_periods]\n",
    "        max distances between all pair of nodes\n",
    "    \"\"\"\n",
    "    numSim, numPeriod, _, _ = N.shape\n",
    "    avg_d = np.empty((numSim, numPeriod-2))\n",
    "    max_d = np.empty((numSim, numPeriod-2))\n",
    "    \n",
    "    for s in range(numSim):\n",
    "        for p in range(1,numPeriod-1):\n",
    "            disG = nx.DiGraph(N[s,p])\n",
    "            dists = shortest_path_length(disG, weight=None)\n",
    "            curlist=[]\n",
    "            for source in dists:\n",
    "                curlist.extend(source[1].values())\n",
    "            avg_d[s,p-1] = sum(curlist) / float(len(curlist))\n",
    "            max_d[s,p-1] = max(curlist)\n",
    "            \n",
    "    return avg_d, max_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Visualize max/avg distances between banks\n",
    "# ###########################\n",
    "# avgg, maxx = dist_avg_max(mx_1n)\n",
    "#\n",
    "# pavg = pd.DataFrame(avgg)\n",
    "# pmax = pd.DataFrame(maxx)\n",
    "# # pavg.mean().plot()\n",
    "# abc = pmax.stack().value_counts().sort_index().plot(\n",
    "#     kind=\"bar\",\n",
    "#     title=\"max distances, 1 interest rates, 50 simulations, 15 periods\",\n",
    "#     figsize=(8,6),\n",
    "#     fontsize=12\n",
    "# )\n",
    "# abc.set_xlabel(\"max distance between any pair of reachable nodes\")\n",
    "# abc.set_ylabel(\"frequncy\")\n",
    "# abc.title.set_fontsize(15)\n",
    "# abc.xaxis.label.set_fontsize(15)\n",
    "# abc.yaxis.label.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_networks(N, model, variables):\n",
    "    \"\"\"\n",
    "    Add weight to network\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    model: scikit learn LogisticRegression\n",
    "        model for default probability\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            for b in range(bankNum):\n",
    "                X = df_1c[np.array(df_1c[\"sim#\"]==s) &\n",
    "                          np.array(df_1c[\"period\"]==p) & \n",
    "                          np.array(df_1c[\"bankID\"]==b)\n",
    "                         ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] *= predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pagerank_numpy(G, alpha=0.85, personalization=None, weight='weight', dangling=None):\n",
    "    \"\"\"\n",
    "    This is basically pagerank_numpy without normalization.\n",
    "    \"\"\"\n",
    "    from networkx.algorithms.link_analysis.pagerank_alg import google_matrix\n",
    "    \n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "    M = google_matrix(G, alpha, personalization=personalization,\n",
    "                      weight=weight, dangling=dangling)\n",
    "    # use numpy LAPACK solver\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M.T)\n",
    "    ind = np.argmax(eigenvalues)\n",
    "    # eigenvector of largest eigenvalue is at ind\n",
    "    largest = np.array(eigenvectors[:, ind]).flatten().real\n",
    "    return dict(zip(G, map(float, abs(largest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_networks(f, N):\n",
    "    \"\"\"\n",
    "    Calculate Page Rank scores for all the networks \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function (2D numpy array -> matrix)\n",
    "        the function to apply to each network (e.g. Page Rank)\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices (netowrks)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    PG: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        Page Rank scores\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    PG = np.empty((simNum, periodNum, bankNum))\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            PG[s, p] = np.array(list(f(nx.DiGraph(N[s, p])).values()))\n",
    "            \n",
    "    return PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's add the weight\n",
    "# ###########################\n",
    "weighted = weigh_networks(mx_1n, final, independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's calculate pagerank\n",
    "# ###########################\n",
    "pg_iter = apply_to_networks(pagerank, weighted)\n",
    "pg_norm = apply_to_networks(pagerank_numpy, weighted)\n",
    "pg_not_norm = apply_to_networks(my_pagerank_numpy, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
