{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# import my own helper functions\n",
    "from read import read_sims_result\n",
    "from clean import cleanup_0IR_exp\n",
    "from clean import cleanup_network\n",
    "\n",
    "# pearson correlation coeffcient\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# deque\n",
    "from collections import deque\n",
    "\n",
    "# deep copy\n",
    "from copy import deepcopy\n",
    "\n",
    "# random [0,1)\n",
    "from random import random\n",
    "\n",
    "# Page Rank\n",
    "from networkx.algorithms.link_analysis.pagerank_alg import pagerank, pagerank_numpy, pagerank_scipy\n",
    "\n",
    "# distance\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "independent = [\"deposits\", \"cash\", \"assets\", \"credit available\", \"wealth\", \"leverage\", \n",
    "         \"dummy-0-leverage\",\n",
    "         \"wealth-lag\", \"deposits-lag\", \"cash-lag\", \"assets-lag\", \"leverage-lag\", \n",
    "         \"credit-available-lag\", \"credit-issued-lag\", \"dummy-0-leverage-lag\",\n",
    "         \"over-leverage-frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.007, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###########################\n",
    "# Read OIR results, and fit the model\n",
    "# ###########################\n",
    "df0 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0622/0IR300s\", 32)\n",
    "df0c = cleanup_0IR_exp(df0, numNode=32, numPeriod=15, numSim=100, balanced=True)\n",
    "\n",
    "X = df0c[independent]\n",
    "y = df0c[\"default-next\"]\n",
    "\n",
    "final = LogisticRegression(penalty=\"l1\", C=0.007)\n",
    "final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no defaults in 0IR\n",
    "# sum(df0[df0[\"defaults due to interest\"]\n",
    "#     +df0[\"defaults due to negative wealth\"]\n",
    "#     +df0[\"defaults due to deposit shock\"] == 0].loc[:,\"dot0\":\"dot30\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Read & process positive IR results\n",
    "# ###########################\n",
    "df_1 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0625/1IR\", 32)\n",
    "mx_1n = cleanup_network(df_1, numNode=32, numPeriod=15, numSim=50)\n",
    "df_1c = cleanup_0IR_exp(df_1, numNode=32, numPeriod=15, numSim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_weight(N, dff, mid):\n",
    "    \"\"\"\n",
    "    Calculate weight for edges\n",
    "    Each debt is divided by lenders' wealth (w/o haircut)，\n",
    "    The result number r is scaled to [0, 1) using g(r)=r/(mid+r)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    df: Pandas dataframe (no cleanup)\n",
    "        where we get banks' wealth (w/o haircut)\n",
    "    mid: int\n",
    "        the debt-to-wealth ratio resulting in 50% probability of spreading default\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    dff[\"book_wealth\"] = (dff[\"assets\"] + dff[\"cash\"] + dff[\"debt owed\"] \n",
    "                         - dff[\"debt to pay\"] - dff[\"deposits\"])\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum+1):\n",
    "            for lender in range(bankNum):\n",
    "                w = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==lender)\n",
    "                       ][\"book_wealth\"].values[0]\n",
    "                \n",
    "                # helper function\n",
    "                def f(a):\n",
    "                    if a > 0: # there is debt\n",
    "                        if w > 0: # positive wealth\n",
    "                            t = a/w\n",
    "                            return t/(t+mid)\n",
    "                        else: # 0 or negative wealth\n",
    "                            return 100/(100+mid)\n",
    "                    else: # no debt or weird data \n",
    "                        return 0\n",
    "                \n",
    "                WN[s, p-1, :, lender] = [f(k) for k in WN[s, p-1, :, lender]]\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_weight(N, dff, model, variables):\n",
    "    \"\"\"\n",
    "    Calculate weight for nodes\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    dff: Pandas dataframe (yes cleanup)\n",
    "        where we get bank's balance sheet info\n",
    "    model: model for default probability\n",
    "        scikit learn LogisticRegression\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        array of predicted probability of default\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    WN = np.empty((simNum, periodNum, bankNum))\n",
    "    WN.fill(-1)\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(2,periodNum):\n",
    "            for b in range(bankNum):\n",
    "                X = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==b)\n",
    "                       ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] = predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights_all = create_edge_weight(mx_1n, df_1, 0.6)\n",
    "node_weights_all = create_node_weight(mx_1n, df_1c, final, independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the debt adjacency matrix in a 2d graph\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(edge_weights_all[0,1], interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_walk_single(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    defaulted = frozenset([i for i in range(num_bank) if solvent[i] == -1])\n",
    "    tempDefault = set(defaulted)\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "#             print(\"initial bank:\", b)\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "            while len(nextDefault) > 0: # queue not empty\n",
    "                n = nextDefault.popleft() # next on the queue\n",
    "                if n not in tempDefault: # not aleady defaulted\n",
    "                    tempDefault.add(n)\n",
    "                    result[n] += 1\n",
    "                    for s in G.successors(n): # creditors of n\n",
    "                        if s not in tempDefault and coin(G.edges[(n,s)]['weight']):\n",
    "                            nextDefault.append(s)\n",
    "#                 print(\"--- currently default:\", tempDefault)\n",
    "#                 print(\"--- death roll:\", nextDefault)\n",
    "            \n",
    "#             print(\"currently default:\", tempDefault)\n",
    "#             print(\"death roll:\", nextDefault)\n",
    "                \n",
    "            tempDefault = set(defaulted)\n",
    "            \n",
    "#         print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_walk_exp(N, solvent, random_walk, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: 3D numpy array [n_simulations, n_periods, n_borrowers, n_lenders] \n",
    "        predicted default probability OR -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: 1D numpy array\n",
    "        index for the bank's default probability   \n",
    "    \"\"\"\n",
    "    n_s, n_p, n_b, _ = N.shape\n",
    "    s_s, s_p, s_b = solvent.shape\n",
    "    big_result = []\n",
    "    \n",
    "    if n_s != s_s or n_p != s_p or n_b != s_b:\n",
    "        raise ValueError('Two arrays have incompatible sizes.')\n",
    "        \n",
    "    for i, j in np.ndindex((n_s,n_p)):\n",
    "        big_result.extend(random_walk(N[i,j],\n",
    "                                      solvent[i,j],\n",
    "                                      iterations=iterations\n",
    "                                     ).values())\n",
    "        \n",
    "    return np.array(big_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prediction = customized_random_walk_exp(edge_weights_all, node_weights_all, customized_random_walk_single, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18240"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28104901574167945, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###########################\n",
    "# pearson correlation coeffcient is not very big \n",
    "# it gets slightly bigger with lots of iterations\n",
    "# ###########################\n",
    "pearsonr(overall_prediction, df_1c[\"default-next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim#</th>\n",
       "      <th>period</th>\n",
       "      <th>bankID</th>\n",
       "      <th>theta (risk aversion)</th>\n",
       "      <th>wealth</th>\n",
       "      <th>deposits</th>\n",
       "      <th>cash</th>\n",
       "      <th>assets</th>\n",
       "      <th>leverage</th>\n",
       "      <th>credit available</th>\n",
       "      <th>...</th>\n",
       "      <th>cash-lag</th>\n",
       "      <th>assets-lag</th>\n",
       "      <th>leverage-lag</th>\n",
       "      <th>credit-available-lag</th>\n",
       "      <th>credit-issued-lag</th>\n",
       "      <th>dummy-0-leverage-lag</th>\n",
       "      <th>over-leverage-frequency</th>\n",
       "      <th>default-next-wealth</th>\n",
       "      <th>default-next-deposit</th>\n",
       "      <th>default-next-interest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default-next</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>...</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "      <td>18079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sim#  period  bankID  theta (risk aversion)  wealth  deposits  \\\n",
       "default-next                                                                   \n",
       "0             18079   18079   18079                  18079   18079     18079   \n",
       "1               161     161     161                    161     161       161   \n",
       "\n",
       "               cash  assets  leverage  credit available  \\\n",
       "default-next                                              \n",
       "0             18079   18079     18079             18079   \n",
       "1               161     161       161               161   \n",
       "\n",
       "                      ...            cash-lag  assets-lag  leverage-lag  \\\n",
       "default-next          ...                                                 \n",
       "0                     ...               18079       18079         18079   \n",
       "1                     ...                 161         161           161   \n",
       "\n",
       "              credit-available-lag  credit-issued-lag  dummy-0-leverage-lag  \\\n",
       "default-next                                                                  \n",
       "0                            18079              18079                 18079   \n",
       "1                              161                161                   161   \n",
       "\n",
       "              over-leverage-frequency  default-next-wealth  \\\n",
       "default-next                                                 \n",
       "0                               18079                18079   \n",
       "1                                 161                  161   \n",
       "\n",
       "              default-next-deposit  default-next-interest  \n",
       "default-next                                               \n",
       "0                            18079                  18079  \n",
       "1                              161                    161  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1c.groupby(\"default-next\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07445464]] [-6.59368762]\n",
      "[[0.07387442]] [-6.57087636]\n",
      "[[0.07505506]] [-6.58777809]\n",
      "[[0.07573527]] [-6.67025016]\n",
      "[[0.07421497]] [-6.60533278]\n",
      "[[0.07405041]] [-6.61022708]\n",
      "[[0.07384716]] [-6.55680261]\n",
      "[[0.07298934]] [-6.55100446]\n",
      "[[0.0748739]] [-6.62324677]\n",
      "[[0.07422177]] [-6.56276799]\n",
      "[[0.07416996]] [-6.56218559]\n",
      "[[0.07328413]] [-6.57165461]\n",
      "[[18051    28]\n",
      " [  156     5]]\n",
      " accuracy:      0.9899122807017543\n",
      " precision:     0.15151515151515152\n",
      " recall:    0.031055900621118012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ###########################\n",
    "# K-fold cross validation\n",
    "# use approx. default probability to predict default\n",
    "# ###########################\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# brier + accuracy = 1\n",
    "\n",
    "fold = 12\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "\n",
    "accuracy = 0\n",
    "conf = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for train_index, test_index in kf.split(overall_prediction):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(overall_prediction[train_index].reshape(-1, 1), \n",
    "              df_1c[\"default-next\"].iloc[train_index])\n",
    "    print(model.coef_, model.intercept_)\n",
    "    accuracy += model.score(overall_prediction[test_index].reshape(-1, 1), \n",
    "                            df_1c[\"default-next\"].iloc[test_index])\n",
    "    conf += confusion_matrix(df_1c[\"default-next\"].iloc[test_index], \n",
    "                             model.predict(overall_prediction[test_index].reshape(-1, 1)))\n",
    "\n",
    "tn, fp, fn, tp = conf.ravel()\n",
    "print(\"{}\\n accuracy:{:24}\\n precision:{:24}\\n recall:{:24}\\n\".format(\n",
    "        conf, \n",
    "        accuracy/fold, \n",
    "        tp/(tp+fp),\n",
    "        tp/(tp+fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "Stuff Below this are old stuff that I might or might not need.\n",
    "----------------------------------------------------------------------\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_avg_max(N):\n",
    "    \"\"\"\n",
    "    calculate average & max distances between all pair of nodes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_d: 2D numpy array [n_simulations, n_periods]\n",
    "        average distances between all pair of nodes\n",
    "    max_d: 2D numpy array [n_simulations, n_periods]\n",
    "        max distances between all pair of nodes\n",
    "    \"\"\"\n",
    "    numSim, numPeriod, _, _ = N.shape\n",
    "    avg_d = np.empty((numSim, numPeriod-2))\n",
    "    max_d = np.empty((numSim, numPeriod-2))\n",
    "    \n",
    "    for s in range(numSim):\n",
    "        for p in range(1,numPeriod-1):\n",
    "            disG = nx.DiGraph(N[s,p])\n",
    "            dists = shortest_path_length(disG, weight=None)\n",
    "            curlist=[]\n",
    "            for source in dists:\n",
    "                curlist.extend(source[1].values())\n",
    "            avg_d[s,p-1] = sum(curlist) / float(len(curlist))\n",
    "            max_d[s,p-1] = max(curlist)\n",
    "            \n",
    "    return avg_d, max_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Visualize max/avg distances between banks\n",
    "# ###########################\n",
    "# avgg, maxx = dist_avg_max(mx_1n)\n",
    "#\n",
    "# pavg = pd.DataFrame(avgg)\n",
    "# pmax = pd.DataFrame(maxx)\n",
    "# # pavg.mean().plot()\n",
    "# abc = pmax.stack().value_counts().sort_index().plot(\n",
    "#     kind=\"bar\",\n",
    "#     title=\"max distances, 1 interest rates, 50 simulations, 15 periods\",\n",
    "#     figsize=(8,6),\n",
    "#     fontsize=12\n",
    "# )\n",
    "# abc.set_xlabel(\"max distance between any pair of reachable nodes\")\n",
    "# abc.set_ylabel(\"frequncy\")\n",
    "# abc.title.set_fontsize(15)\n",
    "# abc.xaxis.label.set_fontsize(15)\n",
    "# abc.yaxis.label.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_networks(N, model, variables):\n",
    "    \"\"\"\n",
    "    Add weight to network\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    model: scikit learn LogisticRegression\n",
    "        model for default probability\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            for b in range(bankNum):\n",
    "                X = df_1c[np.array(df_1c[\"sim#\"]==s) &\n",
    "                          np.array(df_1c[\"period\"]==p) & \n",
    "                          np.array(df_1c[\"bankID\"]==b)\n",
    "                         ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] *= predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pagerank_numpy(G, alpha=0.85, personalization=None, weight='weight', dangling=None):\n",
    "    \"\"\"\n",
    "    This is basically pagerank_numpy without normalization.\n",
    "    \"\"\"\n",
    "    from networkx.algorithms.link_analysis.pagerank_alg import google_matrix\n",
    "    \n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "    M = google_matrix(G, alpha, personalization=personalization,\n",
    "                      weight=weight, dangling=dangling)\n",
    "    # use numpy LAPACK solver\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M.T)\n",
    "    ind = np.argmax(eigenvalues)\n",
    "    # eigenvector of largest eigenvalue is at ind\n",
    "    largest = np.array(eigenvectors[:, ind]).flatten().real\n",
    "    return dict(zip(G, map(float, abs(largest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_networks(f, N):\n",
    "    \"\"\"\n",
    "    Calculate Page Rank scores for all the networks \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function (2D numpy array -> matrix)\n",
    "        the function to apply to each network (e.g. Page Rank)\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices (netowrks)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    PG: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        Page Rank scores\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    PG = np.empty((simNum, periodNum, bankNum))\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            PG[s, p] = np.array(list(f(nx.DiGraph(N[s, p])).values()))\n",
    "            \n",
    "    return PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's add the weight\n",
    "# ###########################\n",
    "weighted = weigh_networks(mx_1n, final, independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's calculate pagerank\n",
    "# ###########################\n",
    "pg_iter = apply_to_networks(pagerank, weighted)\n",
    "pg_norm = apply_to_networks(pagerank_numpy, weighted)\n",
    "pg_not_norm = apply_to_networks(my_pagerank_numpy, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
