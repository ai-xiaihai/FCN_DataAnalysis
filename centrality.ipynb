{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# import my own helper functions\n",
    "from read import read_sims_result\n",
    "from clean import cleanup_0IR_exp\n",
    "from clean import cleanup_network\n",
    "\n",
    "# pearson correlation coeffcient\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# deque\n",
    "from collections import deque\n",
    "\n",
    "# deep copy\n",
    "from copy import deepcopy\n",
    "\n",
    "# random [0,1)\n",
    "from random import random\n",
    "\n",
    "# Page Rank\n",
    "from networkx.algorithms.link_analysis.pagerank_alg import pagerank, pagerank_numpy, pagerank_scipy\n",
    "\n",
    "# distance\n",
    "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "independent = [\"deposits\", \"cash\", \"assets\", \"credit available\", \"wealth\", \"leverage\", \n",
    "         \"dummy-0-leverage\",\n",
    "         \"wealth-lag\", \"deposits-lag\", \"cash-lag\", \"assets-lag\", \"leverage-lag\", \n",
    "         \"credit-available-lag\", \"credit-issued-lag\", \"dummy-0-leverage-lag\",\n",
    "         \"over-leverage-frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.007, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###########################\n",
    "# Read OIR results, and fit the model\n",
    "# ###########################\n",
    "df0 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0622/0IR300s\", 32)\n",
    "df0c = cleanup_0IR_exp(df0, numNode=32, numPeriod=15, numSim=100, balanced=True)\n",
    "\n",
    "X = df0c[independent]\n",
    "y = df0c[\"default-next\"]\n",
    "\n",
    "final = LogisticRegression(penalty=\"l1\", C=0.007)\n",
    "final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure no defaults in 0IR\n",
    "# sum(df0[df0[\"defaults due to interest\"]\n",
    "#     +df0[\"defaults due to negative wealth\"]\n",
    "#     +df0[\"defaults due to deposit shock\"] == 0].loc[:,\"dot0\":\"dot30\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Read & process positive IR results\n",
    "# ###########################\n",
    "df_1 = read_sims_result(\"/Users/xcheng/Documents/Oberlin/Summer2/DataAnalysis/data/0625/1IR\", 32)\n",
    "mx_1n = cleanup_network(df_1, numNode=32, numPeriod=15, numSim=50)\n",
    "df_1c = cleanup_0IR_exp(df_1, numNode=32, numPeriod=15, numSim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_weight(N, dff, mid):\n",
    "    \"\"\"\n",
    "    Calculate weight for edges\n",
    "    Each debt is divided by lenders' wealth (w/o haircut)ï¼Œ\n",
    "    The result number r is scaled to [0, 1) using g(r)=r/(mid+r)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    df: Pandas dataframe (no cleanup)\n",
    "        where we get banks' wealth (w/o haircut)\n",
    "    mid: int\n",
    "        the debt-to-wealth ratio resulting in 50% probability of spreading default\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    dff[\"book_wealth\"] = (dff[\"assets\"] + dff[\"cash\"] + dff[\"debt owed\"] \n",
    "                         - dff[\"debt to pay\"] - dff[\"deposits\"])\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum+1):\n",
    "            for lender in range(bankNum):\n",
    "                w = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==lender)\n",
    "                       ][\"book_wealth\"].values[0]\n",
    "                \n",
    "                # helper function\n",
    "                def f(a):\n",
    "                    if a > 0: # there is debt\n",
    "                        if w > 0: # positive wealth\n",
    "                            t = a/w\n",
    "                            return t/(t+mid)\n",
    "                        else: # 0 or negative wealth\n",
    "                            return 100/(100+mid)\n",
    "                    else: # no debt or weird data \n",
    "                        return 0\n",
    "                \n",
    "                WN[s, p-1, :, lender] = [f(k) for k in WN[s, p-1, :, lender]]\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_weight(N, dff, model, variables):\n",
    "    \"\"\"\n",
    "    Calculate weight for nodes\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    dff: Pandas dataframe (yes cleanup)\n",
    "        where we get bank's balance sheet info\n",
    "    model: model for default probability\n",
    "        scikit learn LogisticRegression\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        array of predicted probability of default\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    WN = np.empty((simNum, periodNum, bankNum))\n",
    "    WN.fill(-1)\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(2,periodNum):\n",
    "            for b in range(bankNum):\n",
    "                X = dff[np.array(dff[\"sim#\"]==s) &\n",
    "                        np.array(dff[\"period\"]==p) & \n",
    "                        np.array(dff[\"bankID\"]==b)\n",
    "                       ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] = predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights_all = create_edge_weight(mx_1n, df_1, 0.6)\n",
    "node_weights_all = create_node_weight(mx_1n, df_1c, final, independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the debt adjacency matrix in a 2d graph\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(edge_weights_all[0,1], interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_walk_single(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 2D numpy array [n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: list \n",
    "        solvent[solvent bank] = predicted default probability\n",
    "        solvent[insolvent bank] = -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: dict {BankID : # of default}\n",
    "        index for the bank's default probability\n",
    "    \"\"\"\n",
    "    num_bank, _ = N.shape\n",
    "    G = nx.DiGraph(N)\n",
    "    nextDefault = deque()\n",
    "    defaulted = frozenset([i for i in range(num_bank) if solvent[i] == -1])\n",
    "    tempDefault = set(defaulted)\n",
    "    probDefault = {i:solvent[i] for i in range(num_bank) if solvent[i] >= 0}\n",
    "    result = dict(zip(list(probDefault.keys()), [0 for _ in probDefault.keys()]))\n",
    "    def coin(p=0.5):\n",
    "        return random() < p\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        for b in probDefault.keys():\n",
    "#             print(\"initial bank:\", b)\n",
    "            if coin(probDefault[b]): \n",
    "                nextDefault.append(b)\n",
    "            while len(nextDefault) > 0: # queue not empty\n",
    "                n = nextDefault.popleft() # next on the queue\n",
    "                if n not in tempDefault: # not aleady defaulted\n",
    "                    tempDefault.add(n)\n",
    "                    result[n] += 1\n",
    "                    for s in G.successors(n): # creditors of n\n",
    "                        if s not in tempDefault and coin(G.edges[(n,s)]['weight']):\n",
    "                            nextDefault.append(s)\n",
    "#                 print(\"--- currently default:\", tempDefault)\n",
    "#                 print(\"--- death roll:\", nextDefault)\n",
    "            \n",
    "#             print(\"currently default:\", tempDefault)\n",
    "#             print(\"death roll:\", nextDefault)\n",
    "                \n",
    "            tempDefault = set(defaulted)\n",
    "            \n",
    "#         print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_random_walk_exp(N, solvent, iterations=10):\n",
    "    \"\"\"\n",
    "    NEW NEW NEW modified random walk algorithm\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    solvent: 3D numpy array [n_simulations, n_periods, n_borrowers, n_lenders] \n",
    "        predicted default probability OR -1\n",
    "    iterations: int\n",
    "        number of iterations\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    result: 1D numpy array\n",
    "        index for the bank's default probability   \n",
    "    \"\"\"\n",
    "    n_s, n_p, n_b, _ = N.shape\n",
    "    s_s, s_p, s_b = solvent.shape\n",
    "    big_result = []\n",
    "    \n",
    "    if n_s != s_s or n_p != s_p or n_b != s_b:\n",
    "        raise ValueError('Two arrays have incompatible sizes.')\n",
    "        \n",
    "    for i, j in np.ndindex((n_s,n_p)):\n",
    "        big_result.extend(customized_random_walk_single(N[i,j], \n",
    "                                                        solvent[i,j], \n",
    "                                                        iterations=iterations\n",
    "                                                       ).values())\n",
    "        \n",
    "    return np.array(big_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prediction = customized_random_walk_exp(edge_weights_all, node_weights_all, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28435375895423526, 0.0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pearson correlation coeffcient is not very big \n",
    "# it gets slightly bigger with lots of iterations\n",
    "pearsonr(overall_prediction, df_1c[\"default-next\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06957806]] [-5.14169066]\n",
      "[[0.07195801]] [-5.19075611]\n",
      "[[0.07508638]] [-5.25283331]\n",
      "[[0.06973751]] [-5.18959742]\n",
      "[[0.06885175]] [-5.15957947]\n",
      "[[0.07250736]] [-5.19995719]\n",
      "[[0.08079058]] [-5.32340788]\n",
      "[[0.07036459]] [-5.2266497]\n",
      "[[0.06147661]] [-5.04879686]\n",
      "[[0.07190421]] [-5.24258101]\n",
      "[[0.06786615]] [-5.27154027]\n",
      "[[0.068674]] [-5.14397034]\n",
      "[[8193   13]\n",
      " [ 125    7]]\n",
      " accuracy:       0.983449090871395\n",
      " brier:    0.016550909128604897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "fold = 12\n",
    "kf = KFold(n_splits=fold, shuffle=True)\n",
    "\n",
    "accuracy = 0\n",
    "conf = np.array([[0, 0], [0, 0]])\n",
    "brier = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(overall_prediction[train_index].reshape(-1, 1), \n",
    "              df_1c[\"default-next\"].iloc[train_index])\n",
    "    print(model.coef_, model.intercept_)\n",
    "    accuracy += model.score(overall_prediction[train_index].reshape(-1, 1), \n",
    "                            df_1c[\"default-next\"].iloc[train_index])\n",
    "    conf += confusion_matrix(df_1c[\"default-next\"].iloc[train_index], \n",
    "                             model.predict(overall_prediction[train_index].reshape(-1, 1)))\n",
    "    brier += brier_score_loss(df_1c[\"default-next\"].iloc[train_index], \n",
    "                              model.predict(overall_prediction[train_index].reshape(-1, 1)))\n",
    "print(\"{}\\n accuracy:{:24}\\n brier:{:24}\\n\".format(\n",
    "        conf, accuracy/fold, brier/fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "Stuff Below this are old stuff that I might or might not need.\n",
    "----------------------------------------------------------------------\n",
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_avg_max(N):\n",
    "    \"\"\"\n",
    "    calculate average & max distances between all pair of nodes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    avg_d: 2D numpy array [n_simulations, n_periods]\n",
    "        average distances between all pair of nodes\n",
    "    max_d: 2D numpy array [n_simulations, n_periods]\n",
    "        max distances between all pair of nodes\n",
    "    \"\"\"\n",
    "    numSim, numPeriod, _, _ = N.shape\n",
    "    avg_d = np.empty((numSim, numPeriod-2))\n",
    "    max_d = np.empty((numSim, numPeriod-2))\n",
    "    \n",
    "    for s in range(numSim):\n",
    "        for p in range(1,numPeriod-1):\n",
    "            disG = nx.DiGraph(N[s,p])\n",
    "            dists = shortest_path_length(disG, weight=None)\n",
    "            curlist=[]\n",
    "            for source in dists:\n",
    "                curlist.extend(source[1].values())\n",
    "            avg_d[s,p-1] = sum(curlist) / float(len(curlist))\n",
    "            max_d[s,p-1] = max(curlist)\n",
    "            \n",
    "    return avg_d, max_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Visualize max/avg distances between banks\n",
    "# ###########################\n",
    "# avgg, maxx = dist_avg_max(mx_1n)\n",
    "#\n",
    "# pavg = pd.DataFrame(avgg)\n",
    "# pmax = pd.DataFrame(maxx)\n",
    "# # pavg.mean().plot()\n",
    "# abc = pmax.stack().value_counts().sort_index().plot(\n",
    "#     kind=\"bar\",\n",
    "#     title=\"max distances, 1 interest rates, 50 simulations, 15 periods\",\n",
    "#     figsize=(8,6),\n",
    "#     fontsize=12\n",
    "# )\n",
    "# abc.set_xlabel(\"max distance between any pair of reachable nodes\")\n",
    "# abc.set_ylabel(\"frequncy\")\n",
    "# abc.title.set_fontsize(15)\n",
    "# abc.xaxis.label.set_fontsize(15)\n",
    "# abc.yaxis.label.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_networks(N, model, variables):\n",
    "    \"\"\"\n",
    "    Add weight to network\n",
    "    Each debt is multiplied by lenders' predicted default probability\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices \n",
    "    model: scikit learn LogisticRegression\n",
    "        model for default probability\n",
    "    variables: a list of strings\n",
    "        independent variables for the model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    WN: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        new weighted debt adjacency matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    WN = np.copy(N)\n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            for b in range(bankNum):\n",
    "                X = df_1c[np.array(df_1c[\"sim#\"]==s) &\n",
    "                          np.array(df_1c[\"period\"]==p) & \n",
    "                          np.array(df_1c[\"bankID\"]==b)\n",
    "                         ][variables].values\n",
    "                if X.any():\n",
    "                    predicted_default_probability = model.predict_proba(X)[0][1]\n",
    "                    WN[s, p-1, b] *= predicted_default_probability\n",
    "                    \n",
    "    return WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pagerank_numpy(G, alpha=0.85, personalization=None, weight='weight', dangling=None):\n",
    "    \"\"\"\n",
    "    This is basically pagerank_numpy without normalization.\n",
    "    \"\"\"\n",
    "    from networkx.algorithms.link_analysis.pagerank_alg import google_matrix\n",
    "    \n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "    M = google_matrix(G, alpha, personalization=personalization,\n",
    "                      weight=weight, dangling=dangling)\n",
    "    # use numpy LAPACK solver\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M.T)\n",
    "    ind = np.argmax(eigenvalues)\n",
    "    # eigenvector of largest eigenvalue is at ind\n",
    "    largest = np.array(eigenvectors[:, ind]).flatten().real\n",
    "    return dict(zip(G, map(float, abs(largest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_networks(f, N):\n",
    "    \"\"\"\n",
    "    Calculate Page Rank scores for all the networks \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function (2D numpy array -> matrix)\n",
    "        the function to apply to each network (e.g. Page Rank)\n",
    "    N: 4D numpy array [n_simulations, n_periods, n_borrowers, n_lenders]\n",
    "        debt adjacency matrices (netowrks)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    PG: 3D numpy array [n_simulations, n_periods, n_banks]\n",
    "        Page Rank scores\n",
    "    \"\"\"\n",
    "    \n",
    "    simNum, periodNum, bankNum, _= N.shape\n",
    "    PG = np.empty((simNum, periodNum, bankNum))\n",
    "    \n",
    "    for s in range(simNum):\n",
    "        for p in range(1,periodNum-1):\n",
    "            PG[s, p] = np.array(list(f(nx.DiGraph(N[s, p])).values()))\n",
    "            \n",
    "    return PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's add the weight\n",
    "# ###########################\n",
    "weighted = weigh_networks(mx_1n, final, independent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# Let's calculate pagerank\n",
    "# ###########################\n",
    "pg_iter = apply_to_networks(pagerank, weighted)\n",
    "pg_norm = apply_to_networks(pagerank_numpy, weighted)\n",
    "pg_not_norm = apply_to_networks(my_pagerank_numpy, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
